{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Model Interpretability and Analysis\n\n",
    "This notebook explores model interpretability to understand which molecular and protein features are important for drug-target interaction predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "import sys\n",
    "sys.path.append('../models')\n",
    "from gnn_models import get_model\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = Path('../data')\n",
    "PROCESSED_DATA = DATA_DIR / 'processed'\n",
    "RAW_DATA = DATA_DIR / 'raw'\n",
    "MODEL_DIR = Path('../models/checkpoints')\n",
    "RESULTS_DIR = Path('../results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load molecular graphs\n",
    "with open(PROCESSED_DATA / 'molecular_graphs' / 'davis_graphs.pkl', 'rb') as f:\n",
    "    davis_mol_graphs = pickle.load(f)\n",
    "\n",
    "# Load protein features\n",
    "with open(PROCESSED_DATA / 'protein_features' / 'davis_protein_fixed.pkl', 'rb') as f:\n",
    "    davis_protein_features = pickle.load(f)\n",
    "\n",
    "# Load original SMILES\n",
    "with open(RAW_DATA / 'davis' / 'ligands_can.txt', 'r') as f:\n",
    "    davis_smiles = json.load(f)\n",
    "\n",
    "# Load affinity data\n",
    "with open(RAW_DATA / 'davis' / 'Y', 'rb') as f:\n",
    "    davis_Y = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Load training results\n",
    "with open(MODEL_DIR / 'training_results.pkl', 'rb') as f:\n",
    "    training_results = pickle.load(f)\n",
    "\n",
    "print(f'Loaded data for {len(davis_mol_graphs)} drugs and {len(davis_protein_features)} proteins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best performing model\n",
    "sample_graph = next(iter(davis_mol_graphs.values()))\n",
    "num_node_features = sample_graph.x.shape[1]\n",
    "protein_feature_dim = next(iter(davis_protein_features.values())).shape[0]\n",
    "\n",
    "# Find best model from results\n",
    "best_model_name = min(training_results.keys(), \n",
    "                     key=lambda x: training_results[x]['test_metrics']['rmse'])\n",
    "\n",
    "print(f'Best model: {best_model_name.upper()}')\n",
    "\n",
    "# Load model\n",
    "model = get_model(\n",
    "    best_model_name,\n",
    "    num_features=num_node_features,\n",
    "    hidden_dim=128,\n",
    "    output_dim=128,\n",
    "    num_layers=3,\n",
    "    dropout=0.2,\n",
    "    protein_dim=protein_feature_dim\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_DIR / f'{best_model_name}_best.pt', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'Model loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_importance(model, mol_graph, protein_features, device):\n",
    "    '''Calculate feature importance using gradients'''\n",
    "    model.eval()\n",
    "    \n",
    "    # Move to device\n",
    "    mol_graph = mol_graph.to(device)\n",
    "    protein_tensor = torch.FloatTensor(protein_features).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Enable gradients for input\n",
    "    mol_graph.x.requires_grad = True\n",
    "    \n",
    "    # Forward pass\n",
    "    batch = Batch.from_data_list([mol_graph])\n",
    "    output = model(batch, protein_tensor)\n",
    "    \n",
    "    # Backward pass\n",
    "    output.backward()\n",
    "    \n",
    "    # Get gradient magnitudes\n",
    "    node_importance = mol_graph.x.grad.abs().mean(dim=1).cpu().numpy()\n",
    "    \n",
    "    return node_importance\n",
    "\n",
    "# Analyze a few drug-protein pairs\n",
    "drug_ids = list(davis_mol_graphs.keys())[:5]\n",
    "protein_ids = list(davis_protein_features.keys())[:5]\n",
    "\n",
    "importance_scores = []\n",
    "\n",
    "for drug_id in drug_ids:\n",
    "    for protein_id in protein_ids:\n",
    "        mol_graph = davis_mol_graphs[drug_id].clone()\n",
    "        protein_features = davis_protein_features[protein_id]\n",
    "        \n",
    "        importance = get_gradient_importance(model, mol_graph, protein_features, device)\n",
    "        importance_scores.append({\n",
    "            'drug': drug_id,\n",
    "            'protein': protein_id,\n",
    "            'importance': importance\n",
    "        })\n",
    "\n",
    "print(f'Calculated importance scores for {len(importance_scores)} drug-protein pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Protein Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_protein_feature_importance(model, mol_graphs, protein_features, device, num_samples=50):\n",
    "    '''Analyze which protein features are most important'''\n",
    "    feature_names = [\n",
    "        'Length', 'Total MW', 'Avg Hydrophobicity', 'Polarity Ratio',\n",
    "        'Cysteine Ratio', 'Basic Residue Ratio', 'Acidic Residue Ratio',\n",
    "        'Hydrophobic Ratio', 'Polar Ratio', 'Aromatic Ratio'\n",
    "    ]\n",
    "    \n",
    "    model.eval()\n",
    "    feature_gradients = []\n",
    "    \n",
    "    # Sample random drug-protein pairs\n",
    "    drug_ids = list(mol_graphs.keys())\n",
    "    protein_ids = list(protein_features.keys())\n",
    "    \n",
    "    for _ in tqdm(range(num_samples), desc='Analyzing protein features'):\n",
    "        # Random selection\n",
    "        drug_id = np.random.choice(drug_ids)\n",
    "        protein_id = np.random.choice(protein_ids)\n",
    "        \n",
    "        # Get data\n",
    "        mol_graph = mol_graphs[drug_id].clone().to(device)\n",
    "        protein_tensor = torch.FloatTensor(protein_features[protein_id]).unsqueeze(0).to(device)\n",
    "        protein_tensor.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        batch = Batch.from_data_list([mol_graph])\n",
    "        output = model(batch, protein_tensor)\n",
    "        \n",
    "        # Backward pass\n",
    "        output.backward()\n",
    "        \n",
    "        # Store gradients\n",
    "        feature_gradients.append(protein_tensor.grad.abs().squeeze().cpu().numpy())\n",
    "    \n",
    "    # Average importance across samples\n",
    "    avg_importance = np.mean(feature_gradients, axis=0)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names[:len(avg_importance)],\n",
    "        'Importance': avg_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Analyze protein features\n",
    "protein_importance = analyze_protein_feature_importance(\n",
    "    model, davis_mol_graphs, davis_protein_features, device, num_samples=50\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(protein_importance['Feature'], protein_importance['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Protein Feature Importance for DTI Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 5 most important protein features:')\n",
    "print(protein_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_prediction_errors(model, mol_graphs, protein_features, affinity_matrix, device, num_samples=50):\n",
    "    '''Analyze where the model makes largest errors'''\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    \n",
    "    drug_ids = list(mol_graphs.keys())\n",
    "    protein_ids = list(protein_features.keys())\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Random selection\n",
    "        i = np.random.randint(len(drug_ids))\n",
    "        j = np.random.randint(len(protein_ids))\n",
    "        \n",
    "        drug_id = drug_ids[i]\n",
    "        protein_id = protein_ids[j]\n",
    "        \n",
    "        # Get true affinity\n",
    "        true_affinity = affinity_matrix[i, j]\n",
    "        if true_affinity >= 30000:  # Skip non-interactions\n",
    "            continue\n",
    "        \n",
    "        true_pkd = -np.log10(true_affinity / 1e9)\n",
    "        \n",
    "        # Get prediction\n",
    "        mol_graph = mol_graphs[drug_id].to(device)\n",
    "        protein_tensor = torch.FloatTensor(protein_features[protein_id]).unsqueeze(0).to(device)\n",
    "        batch = Batch.from_data_list([mol_graph])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_pkd = model(batch, protein_tensor).cpu().item()\n",
    "        \n",
    "        error = abs(pred_pkd - true_pkd)\n",
    "        errors.append({\n",
    "            'drug': drug_id,\n",
    "            'protein': protein_id,\n",
    "            'true_pkd': true_pkd,\n",
    "            'pred_pkd': pred_pkd,\n",
    "            'error': error\n",
    "        })\n",
    "    \n",
    "    errors_df = pd.DataFrame(errors).sort_values('error', ascending=False)\n",
    "    return errors_df\n",
    "\n",
    "# Analyze errors\n",
    "error_analysis = analyze_prediction_errors(\n",
    "    model, davis_mol_graphs, davis_protein_features, davis_Y, device, num_samples=100\n",
    ")\n",
    "\n",
    "if len(error_analysis) > 0:\n",
    "    # Plot error distribution\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(error_analysis['error'], bins=20, edgecolor='black')\n",
    "    plt.xlabel('Absolute Error (pKd)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Error Distribution')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(error_analysis['true_pkd'], error_analysis['pred_pkd'], alpha=0.6)\n",
    "    plt.plot([5, 12], [5, 12], 'r--', alpha=0.5)\n",
    "    plt.xlabel('True pKd')\n",
    "    plt.ylabel('Predicted pKd')\n",
    "    plt.title('Predictions vs Truth')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(error_analysis['true_pkd'], error_analysis['error'], alpha=0.6)\n",
    "    plt.xlabel('True pKd')\n",
    "    plt.ylabel('Absolute Error')\n",
    "    plt.title('Error vs Affinity')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('Top 5 largest prediction errors:')\n",
    "    print(error_analysis.head()[['drug', 'protein', 'true_pkd', 'pred_pkd', 'error']])\n",
    "    print(f'\\nMean absolute error: {error_analysis[\"error\"].mean():.3f} pKd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*50)\n",
    "print('INTERPRETABILITY ANALYSIS COMPLETE')\n",
    "print('='*50)\n",
    "\n",
    "print(f'\\nModel analyzed: {best_model_name.upper()}')\n",
    "print(f'Test RMSE: {training_results[best_model_name][\"test_metrics\"][\"rmse\"]:.4f}')\n",
    "\n",
    "print('\\nKey Findings:')\n",
    "print('1. Protein Feature Importance:')\n",
    "print(f'   - Most important: {protein_importance.iloc[0][\"Feature\"]}')\n",
    "print(f'   - Least important: {protein_importance.iloc[-1][\"Feature\"]}')\n",
    "\n",
    "if len(error_analysis) > 0:\n",
    "    print(f'\\n2. Model Performance:')\n",
    "    print(f'   - Mean absolute error: {error_analysis[\"error\"].mean():.3f} pKd')\n",
    "    print(f'   - Max error: {error_analysis[\"error\"].max():.3f} pKd')\n",
    "    \n",
    "print('\\nInterpretability analysis provides insights into:')\n",
    "print('  - Which molecular substructures are important')\n",
    "print('  - Which protein features drive predictions')\n",
    "print('  - Where the model makes errors')\n",
    "print('  - Patterns in strong vs weak interactions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}